{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code environment\\python\\python3.6\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "mpl.rcParams['font.serif'] = ['SimHei']\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "p = sns.color_palette()\n",
    "sns.set_style(\"darkgrid\",{\"font.sans-serif\":['simhei', 'Arial']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.FacetGrid(dataset, hue=\"标签\", size=5).map(plt.scatter, 1, \"标签\").add_legend()\n",
    "# xxx=dataset[['标签',1,27,31,38,40]]\n",
    "# sns.pairplot(xxx, hue=\"标签\", size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 读入数据：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a1 = OneHotEncoder(sparse = False).fit_transform( trains[['用户性别']] )\n",
    "#a2 = OneHotEncoder(sparse = False).fit_transform( trains[['用户职业']])\n",
    "#a3 = OneHotEncoder(sparse = False).fit_transform( trains[['用户教育程度']])\n",
    "#a4 = OneHotEncoder(sparse = False).fit_transform( trains[['用户婚姻状态']])\n",
    "#a5 = OneHotEncoder(sparse = False).fit_transform( trains[['用户户口类型']])\n",
    "#final_output = np.hstack((a1,a2,a3,a4,a5))\n",
    "#final_output\n",
    "\n",
    "#pandas 自带的get_dummies函数实现one-hot,并构造组合特征\n",
    "# trains = pd.read_csv(\"../feature/训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "# #trains.index = trains['用户标识'].tolist()\n",
    "# train_label=trains[['用户标识','标签']]\n",
    "# trains=pd.get_dummies(trains,columns=trains[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "\n",
    "# tests = pd.read_csv(\"../feature/测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "# #tests.index = tests['用户标识'].tolist()\n",
    "# test_label=tests[['用户标识','标签']]\n",
    "# tests=pd.get_dummies(tests,columns=tests[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(interaction_only=True)\n",
    "# trains=poly.fit_transform(trains)\n",
    "# df = pd.DataFrame(trains.reshape(55596, 326))\n",
    "# df.interpolate(axis=1).values.reshape(trains.shape)\n",
    "# df['用户标识']=df[1].astype(int)\n",
    "# trains=pd.merge(train_label,df,how='inner', on = \"用户标识\")\n",
    "\n",
    "# tests=poly.fit_transform(tests)\n",
    "# df = pd.DataFrame(tests.reshape(13899, 326))\n",
    "# df.interpolate(axis=1).values.reshape(tests.shape)\n",
    "# df['用户标识']=df[1].astype(int)\n",
    "# tests=pd.merge(test_label,df,how='inner', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户信息表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/test.csv\",encoding=\"gb2312\") \n",
    "test = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/train.csv\",encoding=\"gb2312\") \n",
    "test=test.fillna(-1)\n",
    "dataset= pd.concat([train,test],axis=0).reset_index()\n",
    "label=dataset[['用户标识','标签']]\n",
    "dataset=dataset.drop(['index','用户标识'],axis=1)\n",
    "\n",
    "dataset=pd.get_dummies(dataset,columns=dataset[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "#dataset \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3,interaction_only=True) #之前設置的是2，现在改成3，更多的交互特征\n",
    "dataset=poly.fit_transform(dataset)\n",
    "df = pd.DataFrame(dataset.reshape(23899,2325))\n",
    "df.interpolate(axis=1).values.reshape(dataset.shape)\n",
    "\n",
    "#dataset\n",
    "#trains=pd.merge(label,df,left_index=True,right_index=True,how='outer')\n",
    "trains=pd.concat([label,df],axis=1)\n",
    "trains.to_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/feature_total_A.csv\",index=None,encoding=\"gb2312\") #mean填充 69495 rows × 1171 columns 没有删去用户标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户浏览行为训练表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/user_browse_test.csv\",encoding=\"gb2312\") \n",
    "test = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/user_browse_train.csv\",encoding=\"gb2312\") \n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户浏览行为缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#用均值填充缺失值\n",
    "temp.fillna(temp.mean(),inplace=True)\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户银行流水记录表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/bank_train.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/bank_test.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#用均值填充缺失值\n",
    "temp.fillna(temp.mean(),inplace=True)\n",
    "temp\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户账单表初始特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23899, 57)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/bill_prifeature_train.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"D:/Files/QQFiles/935257580/FileRecv/personal loan/feature/bill_prifeature_test.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "print(temp.shape)\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#特征轮：构造放款后与放款前差值特征\n",
    "feature_name=temp.columns \n",
    "for name in feature_name:\n",
    "    if name.find('款后')> 0:\n",
    "        x1=name.replace('款后','款前')\n",
    "        if x1 in feature_name:\n",
    "            temp[name+\"与\"+x1+\"差值\"]=temp[name]-temp[x1]        \n",
    "#用均值填充缺失值\n",
    "temp.fillna(temp.mean(),inplace=True)\n",
    "#temp\n",
    "\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户账单表特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../feature/\\xe7\\x94\\xa8\\xe6\\x88\\xb7\\xe8\\xb4\\xa6\\xe5\\x8d\\x95\\xe8\\xa1\\xa8\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe8\\xae\\xad\\xe7\\xbb\\x83\\xe8\\xa1\\xa820170119_A.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e1661d3ccb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../feature/用户账单表特征训练表20170119_A.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gb2312\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 注意自己数据路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../feature/用户账单表特征测试表20170119_A.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gb2312\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 注意自己数据路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(69495, 466)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\code environment\\python\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\code environment\\python\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\code environment\\python\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\code environment\\python\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\code environment\\python\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../feature/\\xe7\\x94\\xa8\\xe6\\x88\\xb7\\xe8\\xb4\\xa6\\xe5\\x8d\\x95\\xe8\\xa1\\xa8\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe8\\xae\\xad\\xe7\\xbb\\x83\\xe8\\xa1\\xa820170119_A.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../feature/用户账单表特征训练表20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/用户账单表特征测试表20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "print(temp.shape)#(69495, 466)\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#特征轮：构造放款后与放款前差值特征\n",
    "feature_name=temp.columns \n",
    "for name in feature_name:\n",
    "    if name.find('款后')> 0:\n",
    "        x1=name.replace('款后','款前')\n",
    "        if x1 in feature_name:\n",
    "            temp[name+\"与\"+x1+\"差值\"]=temp[name]-temp[x1]        \n",
    "#用均值填充缺失值\n",
    "temp.fillna(temp.mean(),inplace=True)\n",
    "temp#69495 rows × 699 columns\n",
    "\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trains.to_csv(\"../feature/特征汇总_20170119_A.csv\",index=None,encoding=\"gb2312\") #mean填充 69495 rows × 1171 columns 没有删去用户标识\n",
    "#trains.to_csv(\"../feature/特征汇总_20170119_B.csv\",index=None,encoding=\"gb2312\") #0填充  69495 rows × 1171 columns 没有删去用户标识\n",
    "\n",
    "#trains.to_csv(\"../feature/特征汇总_20170119_D.csv\",index=None,encoding=\"gb2312\") #0填充 69495 rows × 1146 columns 当前最高分0.43267\n",
    "#trains.to_csv(\"../feature/特征汇总_20170119_E.csv\",index=None,encoding=\"gb2312\") #mean填充 69495 rows × 1146 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.FacetGrid(dataset, hue=\"标签\", size=5).map(plt.scatter, 1, \"标签\").add_legend()\n",
    "xxx=dataset[['标签',1,27,31,38,40]]\n",
    "sns.pairplot(xxx, hue=\"标签\", size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
