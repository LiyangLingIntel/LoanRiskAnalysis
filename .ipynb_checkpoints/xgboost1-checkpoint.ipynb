{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code environment\\python\\python3.6\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读入数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#a1 = OneHotEncoder(sparse = False).fit_transform( trains[['用户性别']] )\n",
    "#a2 = OneHotEncoder(sparse = False).fit_transform( trains[['用户职业']])\n",
    "#a3 = OneHotEncoder(sparse = False).fit_transform( trains[['用户教育程度']])\n",
    "#a4 = OneHotEncoder(sparse = False).fit_transform( trains[['用户婚姻状态']])\n",
    "#a5 = OneHotEncoder(sparse = False).fit_transform( trains[['用户户口类型']])\n",
    "#final_output = np.hstack((a1,a2,a3,a4,a5))\n",
    "#final_output\n",
    "\n",
    "#pandas 自带的get_dummies函数实现one-hot,并构造组合特征\n",
    "# trains = pd.read_csv(\"../feature/训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "# #trains.index = trains['用户标识'].tolist()\n",
    "# train_label=trains[['用户标识','标签']]\n",
    "# trains=pd.get_dummies(trains,columns=trains[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "\n",
    "# tests = pd.read_csv(\"../feature/测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "# #tests.index = tests['用户标识'].tolist()\n",
    "# test_label=tests[['用户标识','标签']]\n",
    "# tests=pd.get_dummies(tests,columns=tests[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(interaction_only=True)\n",
    "# trains=poly.fit_transform(trains)\n",
    "# df = pd.DataFrame(trains.reshape(55596, 326))\n",
    "# df.interpolate(axis=1).values.reshape(trains.shape)\n",
    "# df['用户标识']=df[1].astype(int)\n",
    "# trains=pd.merge(train_label,df,how='inner', on = \"用户标识\")\n",
    "\n",
    "# tests=poly.fit_transform(tests)\n",
    "# df = pd.DataFrame(tests.reshape(13899, 326))\n",
    "# df.interpolate(axis=1).values.reshape(tests.shape)\n",
    "# df['用户标识']=df[1].astype(int)\n",
    "# tests=pd.merge(test_label,df,how='inner', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户信息表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"../feature/训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test=test.fillna(-1)\n",
    "\n",
    "dataset= pd.concat([train,test],axis=0).reset_index()\n",
    "label=dataset[['用户标识','标签']]\n",
    "dataset=dataset.drop(['index','用户标识'],axis=1)\n",
    "\n",
    "dataset=pd.get_dummies(dataset,columns=dataset[['用户性别','用户职业','用户教育程度','用户婚姻状态','用户户口类型']]).drop(['标签'],axis=1)\n",
    "dataset #69495 rows × 24 columns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "dataset=poly.fit_transform(dataset)\n",
    "df = pd.DataFrame(dataset.reshape(69495,301))\n",
    "df.interpolate(axis=1).values.reshape(dataset.shape)\n",
    "\n",
    "#dataset\n",
    "#trains=pd.merge(label,df,left_index=True,right_index=True,how='outer')\n",
    "trains=pd.concat([label,df],axis=1)\n",
    "trains#69495 rows × 303 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户浏览行为表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../feature/用户浏览行为测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/用户浏览行为训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户浏览行为缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#用均值填充缺失值\n",
    "#temp.fillna(temp.mean(),inplace=True)\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")\n",
    "trains#69495 rows × 343columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户银行流水记录表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../feature/用户银行流水记录训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/用户银行流水记录测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#用均值填充缺失值\n",
    "#temp.fillna(temp.mean(),inplace=True)\n",
    "#temp\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")\n",
    "trains#69495 rows × 369  columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户账单表初级特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../feature/用户账单表初级特征训练表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/用户账单表初级特征测试表_20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "print(temp.shape)\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#特征轮：构造放款后与放款前差值特征\n",
    "feature_name=temp.columns \n",
    "for name in feature_name:\n",
    "    if name.find('款后')> 0:\n",
    "        x1=name.replace('款后','款前')\n",
    "        if x1 in feature_name:\n",
    "            temp[name+\"与\"+x1+\"差值\"]=temp[name]-temp[x1]        \n",
    "#用均值填充缺失值\n",
    "#temp.fillna(temp.mean(),inplace=True)\n",
    "#temp\n",
    "\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")\n",
    "trains#69495 rows × 448  columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户账单表特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../feature/用户账单表特征训练表20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "test = pd.read_csv(\"../feature/用户账单表特征测试表20170119_A.csv\",encoding=\"gb2312\") # 注意自己数据路径\n",
    "dataset= pd.concat([train,test],axis=0)\n",
    "temp=dataset[:]\n",
    "print(temp.shape)#(69495, 466)\n",
    "#统计行和列的缺失值数\n",
    "dataset=dataset.fillna(-1)\n",
    "temp['用户银行流水记录缺失统计']=(dataset==-1).sum(axis=1)\n",
    "#特征轮：构造放款后与放款前差值特征\n",
    "feature_name=temp.columns \n",
    "for name in feature_name:\n",
    "    if name.find('款后')> 0:\n",
    "        x1=name.replace('款后','款前')\n",
    "        if x1 in feature_name:\n",
    "            temp[name+\"与\"+x1+\"差值\"]=temp[name]-temp[x1]        \n",
    "#用均值填充缺失值\n",
    "#temp.fillna(temp.mean(),inplace=True)\n",
    "#temp#69495 rows × 699 columns\n",
    "\n",
    "trains=pd.merge(trains,temp,how='left', on = \"用户标识\")\n",
    "trains=trains.rename(index=str, columns={\"用户标识\": \"userid\"})\n",
    "trains#69495 rows × 1146 columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
